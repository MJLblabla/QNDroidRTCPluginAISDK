# 七牛rtc 接入 AI 能力

## 快速接入

### 依赖配置

  ```
   implementation files('libs/qndroid-rtc-ai-version.jar')//ai sdk
   implementation files('libs/qndroid-rtc-3.1.0.jar') //依赖 rtc 3.1.0版本以上
   implementation'com.qiniu:happy-dns:xxx'
   implementation'com.squareup.okhttp3:okhttp:xxx'
   implementation"org.java-websocket:Java-WebSocket:xxx"
   implementation"org.jetbrains.kotlinx:kotlinx-coroutines-android:x.x.x"
  ```

### 模块初始化

```java
class QNRtcAISdkManager {

    static void init(
            Context appContext,         // 安卓application context
            String aiToken,            // ai能力的token
            SignCallback signCallback   // 请求url签名回调
    );

    //如果过期可以单独重置token
    static void resetToken(String aiToken);

    //请求url签名回调
    interface SignCallback {

        /** 将url签名成token 此方法在子线程中
         * @param url 请求URL中已经包含了时间戳
         * @return 签名后的token
         */
        public String signUrlToToken(String url);
    }
}
```

### aiToken 和url签名

#### aiToken

```
// app_id 加上过期时间
src="<app_id>:<expiration>"
encodedSrc=urlsafe_base64_encode(src)
// 计算HMAC-SHA1签名，并对签名结果做URL安全的Base64编码
sign=hmac_sha1(encodedSrc,"Your_Secret_Key")
encodedSign=urlsafe_base64_encode(sign)
// 拼接上述结果得到 token
token="QD "+Your_Access_Key+":"+encodedSign+":"+encodedSrc``
```

涉及到用户_Secret_Key 建议签名逻辑运行在接入方服务器端

### url签名

public String signUrlToToken(String url)中参数为待签名的url（url中已经包含了时间戳）
[将url签名成token 参考](https://developer.qiniu.com/kodo/1202/download-token)
涉及到用户_Secret_Key 建议此逻辑房间服务器端

涉及到用户_Secret_Key 建议签名逻辑运行在接入方服务器端

### 绑定rtc轨道的ai能力

```java
import android.graphics.Bitmap;
import android.graphics.Color;
import android.os.Bundle;
import android.view.View;

import androidx.annotation.NonNull;
import androidx.annotation.Nullable;
import androidx.appcompat.app.AppCompatActivity;

import com.qiniu.droid.rtc.ai.*;
import com.qiniu.whiteboard.*;

import java.util.ArrayList;
import java.util.List;


public class RoomActivity extends AppCompatActivity {

    private QNSurfaceView mLocalVideoSurfaceView;
    private QNSurfaceView mRemoteVideoSurfaceView;
    private QNRTCClient mClient;

    //本地轨道 用于ai识别本地轨道 其他轨道同理
    QNTrack videoTrack;
    QNTrack audioTrack;

    @Override
    protected void onCreate(Bundle savedInstanceState) {

        // 在布局文件上配置本地预览窗口和远端预览窗口两个 QNSurfaceView
        mLocalVideoSurfaceView = findViewById(R.id.local_video_surface_view);
        mRemoteVideoSurfaceView = findViewById(R.id.remote_video_surface_view);

        // 初始化 QNRTC
        QNRTC.init(
                getApplicationContext(),
                // 配置默认摄像头 ID，此处配置为前置摄像头；配置摄像头采集的分辨率和 FPS
                new QNRTCSetting().setCameraID(QNCameraFacing.FRONT).setCameraPreviewFormat(new QNVideoFormat(640, 480, 30)),
                new QNRTCEventListener() {
                    @Override
                    public void onPlaybackDeviceChanged(QNAudioDevice device) {
                    }

                    @Override
                    public void onCameraError(int errorCode, String errorMessage) {
                    }
                });

        // 创建 QNRTCClient
        mClient = QNRTC.createClient(new QNClientEventListener() {
            @Override
            public void onConnectionStateChanged(QNConnectionState state) {
            }

            @Override
            public void onLeft() {
                // 自己离开房间成功的通知，调用 mClient.leave() 成功之后回调此方法
                RoomActivity.this.finish();
            }

            @Override
            public void onSubscribed(String remoteUserID, List<QNTrack> trackList) {
                for (QNTrack track : trackList) {
                    if (track.getTag().equals("camera")) {
                        // 设置渲染窗口
                        track.play(mRemoteVideoSurfaceView);
                        mRemoteVideoSurfaceView.setVisible(VISIBLE);
                    }
                }
            }

            @Override
            public void onUserJoined(String remoteUserID, String userData) {
                // 远端用户加入房间时会回调此方法，此时可在 UI 上提示，有用户进入房间
            }

            @Override
            public void onUserLeft(String remoteUserID) {
                // 远端用户离开房间时会回调此方法，此时可在 UI 上提示，有用户离开房间
            }

            @Override
            public void onUserPublished(String remoteUserID, List<QNTrack> trackList) {
                // 远端用户发布 tracks 时会回调此方法，SDK 会自动为您订阅对方发布的 tracks
            }

            @Override
            public void onUserUnpublished(String remoteUserID, List<QNTrack> trackList) {
                // 远端用户取消发布时会回调此方法，SDK 会把之前订阅的 tracks 自动为您取消订阅
                for (QNTrack track : trackList) {
                    if (track.getTag().equals("camera")) {
                        mRemoteVideoSurfaceView.setVisible(GONE);
                    }
                }
            }

            @Override
            public void onUserReconnecting(String remoteUserID) {
                // 远端用户断线重连时会回调此方法，此时可在 UI 上提示，对方正在重连
            }

            @Override
            public void onUserReconnected(String remoteUserID) {
                // 远端用户重连成功时会回调此方法，此时可在 UI 上提示，对方已经重连成功
            }
        });
    }

    //绑定自己的控制器事件
    void initView() {

        //点击了开始语音识别按钮翻译自己的轨道
        btnStartAudioToText.setOnClickListener((View.OnClickListener) v -> {
            onClickQNAudioToText(audioTrack);
        });

        //点击停止语音识别
        btnStopAudioToText.setOnClickListener((View.OnClickListener) v -> {
            onClickStopQNAudioToText();
        });

        //点击了自己轨道的身份证识别
        btnIdCardDetector.setOnClickListener((View.OnClickListener) v -> {
            onClickQNIDCardDetector(videoTrack);
        });
    }

    //点击了活体检测 指名分析那个轨道
    void onClickQNFaceActionLive(QNTrack track) {
        QNFaceActLiveParam param = new QNFaceActLiveParam();
        List<QNFaceActAction> actions = new ArrayList<QNFaceActAction>();
        actions.add(QNFaceActAction.NOD);//添加点点头识别
        actions.add(QNFaceActAction.SHAKE);//摇摇头识别
        param.actionTypes = actions;
        //开始活体检测
        QNFaceActionLiveDetector faceActLiveDetector = QNFaceActionLiveDetector.start(
                track, param
        );
        //取消活体检测
        faceActLiveDetector.cancel();
        dealy(2000);
        //假如两秒后用户动作完成
        //提交检测结果
        faceActLiveDetector.commit(new QNFaceActLiveDetector.QNFaceActLiveCallback() {
            @Override
            public void onResult(QNFaceActLive faceActLive) {
            }
        });
    }

    private QNAudioToTextAnalyzer audioToTextAnalyzer;

    //点击了语音转文字 指名分析那个轨道
    void onClickQNAudioToText(QNTrack track) {
        audioToTextAnalyzer = QNAudioToTextAnalyzer.start(
                track,//要转化的轨道
                new AudioToTextParam(),//参数设置 可以使用默认
                new QNAudioToTextAnalyzer.QNAudioToTextCallback() {
                    @Override
                    public void onAudioToText(QNAudioToText audioToText) {
                    }
                }
        );
    }

    //停止语音转文字
    void onClickStopQNAudioToText() {
        audioToTextAnalyzer.stop();
    }

    //点击人脸对比 指名分析那个轨道
    void onClickQNFaceComparer(QNTrack track) {
        //选择目标要对比的图片
        Bitmap targetImg = selectImg();
        QNFaceComparer.run(track, targetImg, null, new QNIDCardDetector.QNIDCardDetectCallback() {
            @Override
            public void onResult(QNIDCardDetect idCardDetect) {

            }
        });
    }

    //点击人脸检测 指名分析那个轨道
    void onClickQNFaceDetector(QNTrack track) {
        QNFaceDetector.run(track, new QNFaceDetectParam(), new QNFaceDetector.QNFaceDetectCallback() {
            @Override
            public void onResult(QNFaceDetect faceDetect) {
            }
        });
    }

    //点击身份证识别 指名分析那个轨道
    void onClickQNIDCardDetector(QNTrack track) {
        QNIDCardDetector.run(videoTrack, null, new QNIDCardDetector.QNIDCardDetectCallback() {
            @Override
            public void onResult(QNIDCardDetect idCardDetect) {

            }
        });
    }

    //光线活体检测
    void onClickFaceFlashLive(QNTrack track) {
        QNFaceFlashLiveDetector faceFlashLiveDetector = QNFaceFlashLiveDetector.start(track);
        //todo 提示信息
        faceFlashLiveDetector.commit(new QNFaceFlashLiveDetector.QNFaceFlashLiveCallback() {
            @Override
            public void onResult(QNFaceFlashLive flashLive) {

            }
        });
    }

    //语音转文字
    void onClickTTS() {
        QNTTSParam param = new QNTTSParam();
        param.text = etText;
        QNTextToSpeakAnalyzer.run(param, new QNTextToSpeakAnalyzer.QNTextToSpeakCallback() {
            @Override
            public void onResult(QNTextToSpeak textToSpeak) {
                paly(textToSpeak.audioBytes);
            }
        });
    }


    void onClickJoinBtn() {
        // 加入房间
        mClient.join(mRoomToken, new QNJoinResultCallback() {
            public void onJoined() {
                // 创建一路以摄像头采集为数据源的视频 track
                videoTrack = QNRTC.createCameraVideoTrack(
                        // 设置摄像头 track 的编码参数，包括分辨率，FPS，码率
                        new QNCameraVideoTrackConfig("camera").setVideoEncodeFormat(new QNVideoFormat(640, 480, 30)).setBitrate(1500 * 1000)
                );
                // 设置摄像头采集的预览窗口
                videoTrack.play(mLocalVideoSurfaceView)

                // 创建一路以麦克风采集为数据源的音频 track
                audioTrack = QNRTC.createMicrophoneAudioTrack(
                        new QNMicrophoneAudioTrackConfig("microphone").setBitrate(100 * 1000)
                );

                // 加入房间成功，即可在房间内发布自己的音频和视频轨道
                mClient.publish(videoTrack, audioTrack);
            }

            public void onError(int errorCode, String errorMessage) {
                // 加入房间失败，可在 UI 提示
            }
        });
    }

    void onClickLeaveBtn() {
        // 离开房间
        mClient.leave();
    }

    @Override
    protected void onDestroy() {
        // 取消初始化 QNRTC
        QNRTC.deinit();
    }

    @Override
    protected void onResume() {
        super.onResume();
        // 程序切到前台，此时需开启摄像头采集
        QNRTC.startCameraCapture();
    }

    @Override
    protected void onPause() {
        super.onPause();
        // 程序切到后台，此时需停止摄像头采集
        QNRTC.stopCameraCapture();
    }
}
```

## api说明

### 活体检测

```java
class QNFaceActionLiveDetector {
    static QNFaceActionLiveDetector start(QNTrack videoTrack, QNFaceActionLiveParams params); // 开始活体动作检测

    void commit(QNFaceActionLiveCallback callback); // 动作结束提交获取识别结果

    void cancel(); // 取消
}

// 活体检测参数
class QNFaceActionLiveParams {
    java.util.List<QNFaceAction> actionTypes; // 动作列表
}

enum QNFaceAction {
    BLINK, // 眨眨眼
    MOUTH, // 张张嘴
    NOD,   // 点点头
    SHAKE // 摇摇头
}

interface QNFaceActionLiveCallback {
    void onResult(QNFaceActionLive faceActLive); // 活体检测结果回调
}

class QNFaceActionLive {
    // 最优帧列表，列表中每个元素格式是 json，包括 base64 编码的二进制图片数据和图像质量分数
    java.util.List<QNFaceActionLive.BestFramesDTO> bestFrames;
    int errorCode; // 请求返回码
    String errorMsg; // 错误提示
    int liveStatus; // 返回动作活体状态码，1 表示通过，0 表示不通过

    class BestFramesDTO {
        String imageB64; // base64 编码的二进制图像数据
        double quality;  // 图像质量分数, 取值范围是[0,100]
    }
};
```

```
QNFaceActLiveParam param = new QNFaceActLiveParam();
List<QNFaceActAction> actions=new ArrayList<QNFaceActAction>();
actions.add(QNFaceActAction.NOD);//添加点点头识别
actions.add(QNFaceActAction.SHAKE);//摇摇头识别
param.actionTypes=actions;
//开始活体检测
QNFaceActLiveDetector faceActLiveDetector=QNFaceActLiveDetector.start(videoTrack,param);
//取消活体检测
faceActLiveDetector.cancel();
//提交检测结果
faceActLiveDetector.commit(new QNFaceActLiveDetector.QNFaceActLiveCallback(){
    @Override
    public void onResult(QNFaceActLive faceActLive){
        }
});
```

### 语音转文字

```java
class QNAudioToTextAnalyzer {
    static QNAudioToTextAnalyzer start(QNTrack audioTrack, QNAudioToTextParams params, QNAudioToTextCallback callback); // 开始语音实时识别

    void stop(); // 停止语音实时识别
}

// 语音识别参数
class QNAudioToTextParam {
    int forceFinal;  // 是否在text为空的时候返回final信息, 1->强制返回;0->不强制返回。
    int maxSil;      // 最长静音间隔，单位秒，默认10s
    int modelType;   // 0->cn; 默认0
    int needPartial; // 是否返回partial文本，1->返回，0-> 不返回;默认1
    int needVad;     // 是否需要vad;0->关闭;1->开启; 默认1
    int needWords;   // 是否返回词语的对齐信息，1->返回， 0->不返回;默认0。
    double vadSilThres; // vad断句的累积时间，大于等于0， 如果设置为0，或者没设置，系统默认
    String hotWords; //  提供热词，格式为: hot_words=热词1,因子1;热词2,因子2，每个热词由热词本身和方法因子以英文逗号隔开，不同热词通过;隔开，最多100个热词，每个热词40字节以内。由于潜在的http服务对url大小的限制，以实际支持的热词个数为准 因子范围[-10,10], 正数代表权重权重越高，权重越高越容易识别成这个词，建议设置1 ，负数代表不想识别

}

// 实时语音转文字回调
interface QNAudioToTextCallback {
    void onAudioToText(QNAudioToText audioToText); // 实时转化文字数据

    void onError(int code, String errMsg); // 错误

    void onStart(); // 开始成功

    void onStop(); // 实时转化结束
}

// 语音识别结果
// 当前片段的结果文字数据，开始到结束过程中会实时返回数据，包含当前一句中的总结果和当前语音片段的结果
class QNAudioToText {
    double startTime; // 该片段的起始时间，毫秒
    double endTime;   // 该片段的终止时间，毫秒
    int ended;      // 是否是websocket最后一条数据,0:非最后一条数据,1: 最后一条数据。
    int endSeq;     // 为该文本所在的切片的终点(包含)，否则为-1
    int finalX;     // 分片结束,当前消息的transcript为该片段最终结果，否则为partial结果
    int longSil;    // 是否长时间静音，0:否;1:是
    int segBegin;   // 是否分段开始: 1:是; 0:不是。
    int segIndex;   // 是否是vad分段开始说话的开始1:是分段开始说话; 0:不是。
    int spkBegin;   // 是否是vad分段开始说话的开始1:是分段开始说话; 0:不是。
    int startSeq;   // 该文本所在的切片的起点(包含), 否则为-1
    String uuid;    // 服务端生成的uuid
    String transcript; // 语音的文本, 如果final=0, 则为partinal结果 (后面可能会更改),final=1为该片段最终结果
    String partialTranscript;  // partial结果文本, 开启needpartial后返回
    java.util.List<QNAudioToText.WordsDTO> words; // 返回词语的对齐信息, 参数need_words=1时返回详细内存见下表。

    class WordsDTO {
        double segEnd;   // 该词语相对整个数据流的起始时间, 毫秒
        double segStart; // 该词语相对当前分段的起始时间, 毫秒
        double voiceEnd;   // 该词语相对整个数据流的终止时间, 毫秒
        double voiceStart; // 该词语相对当前分段的终止时间, 毫秒
        String word; // 词语本身，包括标点符号
    }
};
```

```
    // example:
QNAudioToTextAnalyzer audioToTextAnalyzer = QNAudioToTextAnalyzer.start(
     audioTrack,//要转化的轨道
     new AudioToTextParam(),//参数设置 可以使用默认
     new QNAudioToTextAnalyzer.QNAudioToTextCallback() {
           @Override
           public void onAudioToText(QNAudioToText audioToText) {}
     }
);
//停止语音转文字
audioToTextAnalyzer.stop()
```

### 人脸对比

```java
class QNFaceComparer {
    // videoTrack - 视频轨道；targetImg - 目标要对比的图片；params - 参数；callback - 回调
    static void run(QNTrack videoTrack, android.graphics.Bitmap targetImg, QNFaceCompareParam param, QNFaceCompareCallback callback); // 开始一次人脸对比
}

// 人脸对比参数
class QNFaceCompareParam {
    boolean maxFaceA;    // 图像 A 中检测到多张人脸时是否取最大区域的人脸作为输出，默认值为 True
    boolean maxFaceB;    // 图像 B 中检测到多张人脸时是否取最大区域的人脸作为输出，默认值为 True
    boolean rotateA;     // 人脸检测失败时，是否对图像 A 做旋转再检测，旋转角包括 90、180、270 三个角度，默认值为 False
    boolean rotateB;     // 人脸检测失败时，是否对图像 B 做旋转再检测，旋转角包括 90、180、270 三个角度，默认值为 False
}

// 人脸对比结果
class QNFaceCompare {
    int errorCode; // 请求返回码
    string errorMsg; // 错误提示
    double similarity; //相似度
}

// 人脸对比回调
interface QNFaceCompareCallback {
    void onResult(QNFaceCompare faceCompare); // 比较结果回调
}
```

```
// example:
QNFaceComparer.run(videoTrack,targetImg,null,new QNIDCardDetector.QNIDCardDetectCallback(){
    @Override
    public void onResult(IDCardDetect idCardDetect){}
});
```

### 人脸检测

```java
class QNFaceDetector {
    // 开始一次人脸检测
    static void run(QNTrack videoTrack, QNFaceDetectParams params, QNFaceDetectCallback callback);
}

// 人脸检测参数
class QNFaceDetectParam {
    boolean rotate; // 人脸检测失败时，是否对图像 A 做旋转再检测，旋转角包 括 90、180、270 三个角度，默认值为 False
}

// 人脸检测回调
interface QNFaceDetectCallback {
    void onResult(QNFaceDetect faceDetect); // 人脸检测结果
}

// 人脸检测结果
class QNFaceDetect {
    int errorCode;   // 请求返回码
    String errorMsg; // 错误提示
    int numFace;     // 图像中人脸数量
    int rotateAngle; // 图像旋转角度
    java.util.List<FaceDTO> faces; // [face1,face2,…]，其中 face1,face2,…等为 json 格式，具体格式见下表

    class FaceDTO {
        int age;     // 年龄，区间 1-107 岁
        double area;// 人脸区域的大小
        double blur; // 人脸模糊度，取值范围[0,1]，越大越清晰
        double completeness; // 取值0到100；0表示人脸不完整，溢出了图像边界，100 表示人脸是完整的，在图像边界内
        double eye; // 闭眼概率,取值范围[0,100]
        String faceAlignedB64;// 使用 base64 编码的对齐后人脸图片数据
        double faceZize; // 人脸尺寸分数，取值分数[0,100]， 越大人脸尺寸越大
        String gender;   // 性别，’M’代表男，’F’代表女
        int height;     // 人脸框的高度
        double illumination; // 人脸光照范围，取值范围[0,100]，越大光照质量越好
        double mouth;// 闭嘴概率,取值范围[0,100]
        double pitch;// 三维旋转之俯仰角，[-180,180]
        double quality;// 人脸综合质量分数，取值范围[0,100], 越大质量越好
        double roll; // 三维旋转之左右旋转角, [-180,180]
        double score;// 人脸分数 取值范围 [0,100]
        int width;   // 人脸框的宽度
        int x;       // 人脸框的左上角 x 坐标
        int y;       // 人脸框的左上角 y 坐标
        double yaw; // 三维旋转之旋转角，[-180,180]
        FaceShapeDTO faceShape;// 人脸尺寸分数，取值分数[0,100]， 越大人脸尺寸越大


        class FaceShapeDTO {
            java.util.List<FaceProfileDTO> faceProfile;
            java.util.List<FaceProfileDTO> leftEye;
            java.util.List<FaceProfileDTO> leftEyebrow;
            java.util.List<FaceProfileDTO> mouth;
            java.util.List<FaceProfileDTO> nose;
            java.util.List<FaceProfileDTO> pupil;
            java.util.List<FaceProfileDTO> rightEye;
            java.util.List<FaceProfileDTO> rightEyebrow;

            // 人脸部位坐标
            class FaceProfileDTO {
                int x;
                int y;
            }
        }
    }
}
```

```
// example:
QNFaceDetector.run(videoTrack,new QNFaceDetectParam(),new QNFaceDetector.QNFaceDetectCallback(){
    @Override
    public void onResult(QNFaceDetect faceDetect){ }
});
```

### 身份证识别

```java
class QNIDCardDetector {
    // 开始一次身份证识别
    static void run(QNTrack videoTrack, QNIDCardDetectParam param, QNIDCardDetectCallback callback)
}

// 身份证识别请求参数
class QNIDCardDetectParam {
    boolean enableBorderCheck // 身份证遮挡检测开关，如果输入图片中的身份证卡片边框不完整则返回告警
    boolean enableDetectCopy  // 复印件、翻拍件检测开关，如果输入图片中的身份证卡片是复印件，则返回告警
    String refSide     // 当图片中同时存在身份证正反面时，通过该参数指定识别的版面:取值'Any' - 识别人像面或国徽面，'F' - 仅 识别人像面，'B' - 仅识别国徽面
    boolean retImage    // 是否返回识别后的切图(切图是指精确剪裁对齐后的身份证正反面图片)，返回格式为 JPEG 格式二进制图片使用 base64 编码后的字符串
    boolean retPortrait // 是否返回身份证(人像面)的人脸图 片，返回格式为 JPEG 格式二进制图片使用 base64 编码后的字符串
    Boolean isMirror = true  //当前图片是不是镜像,在没有调整的情况下 通常前置摄像头是镜像图片,后置摄像头不是,默认镜像
}

// 身份证识别结果回调
interface QNIDCardDetectCallback {
    void onResult(QNIDCardDetect idCardDetect)
}

// 身份证识别结果
class QNIDCardDetect {
    int errorCode   // 请求返回码
    String errorMsg // 错误提示
    QNIDCardDetect.ImageResultDTO imageResult // 图片检测结果
    QNIDCardDetect.OCRResultDTO ocrResult // 文字识别结果

    class ImageResultDTO {
        java.util.List<java.util.List<Integer>> idCardBox  // 框坐标，格式为 [[x0, y0], [x1, y1], [x2, y2], [x3, y3]]
        String idcard;    //身份证区域图片，使用Base64 编码后的字符串， 是否返回由请求参数ret_image 决定
        String portrait;//	身份证人像照片，使用Base64 编码后的字符串， 是否返回由请求参数ret_portrait 决定
    }

    class OCRResultDTO {
        String address   // 地址(人像面)
        String birthDate // 生日(人像面) eg. "19900111"
        String gender    // 性别(人像面)
        String idno      // 身份号码(人像面)
        String issuedBy  // 签发机关(国徽面)
        String name      // 姓名(人像面)
        String nation    // 民族(人像面)
        String side      // F-身份证人像面，B-身份 证国徽面
        String validthru // 有效期(国徽面) eg. "20001010-20101009"
    }
}
```

```
// example:
QNIDCardDetector.run(videoTrack,null,new QNIDCardDetector.QNIDCardDetectCallback(){
    @Override
    public void onResult(QNIDCardDetect idCardDetect){}
});
```

```java
class QNRtcAISdkManager {

    static void init(
            Context appContext,         // 安卓application context
            String aiToken,              //ai能力的token
            SignCallback signCallback   //  请求url签名回调
    )

    //如果过期可以单独重置token
    static void resetToken(String aiToken)

    interface SignCallback {

        /** 将url签名成token
         * @param url 请求URL
         * @return 签名后的token
         */
        public String signUrlToToken(String url);
    }
}
```

### 活体检测

```java
class QNFaceActionLiveDetector {
    static QNFaceActionLiveDetector start(QNTrack videoTrack, QNFaceActionLiveParams params) // 开始活体动作检测

    void commit(QNFaceActionLiveCallback callback) // 动作结束提交获取识别结果

    void cancel() // 取消
}

// 活体检测参数
class QNFaceActionLiveParams {
    java.util.List<QNFaceAction> actionTypes // 动作列表
}

enum QNFaceAction {
    BLINK // 眨眨眼
    MOUTH // 张张嘴
            NOD   // 点点头
    SHAKE // 摇摇头
    }

interface QNFaceActionLiveCallback {
    void onResult(QNFaceActionLive faceActLive) // 活体检测结果回调
}

class QNFaceActionLive {
    // 最优帧列表，列表中每个元素格式是 json，包括 base64 编码的二进制图片数据和图像质量分数
    java.util.List<QNFaceActionLive.BestFramesDTO> bestFrames
    int errorCode // 请求返回码
    String errorMsg // 错误提示
    int liveStatus // 返回动作活体状态码，1 表示通过，0 表示不通过

    class BestFramesDTO {
        String imageB64 // base64 编码的二进制图像数据
        double quality  // 图像质量分数, 取值范围是[0,100]
    }
}
```

```
// example:
QNFaceActLiveParam param = new QNFaceActLiveParam();
List<QNFaceActAction> actions = new ArrayList<QNFaceActAction>();
actions.add(QNFaceActAction.NOD);//添加点点头识别
actions.add(QNFaceActAction.SHAKE);//摇摇头识别
param.actionTypes=actions;
//开始活体检测
QNFaceActLiveDetector faceActLiveDetector=QNFaceActLiveDetector.start(videoTrack,param );
//取消活体检测
faceActLiveDetector.cancel();
//提交检测结果
faceActLiveDetector.commit(new QNFaceActLiveDetector.QNFaceActLiveCallback(){
    @Override
    public void onResult(QNFaceActLive faceActLive){ }
});
```

### 语音转文字

```java
class QNAudioToTextAnalyzer {
    static QNAudioToTextAnalyzer start(QNTrack audioTrack, QNAudioToTextParams params, QNAudioToTextCallback callback) // 开始语音实时识别

    void stop() // 停止语音实时识别
}

// 语音识别参数
class QNAudioToTextParam {
    int forceFinal  // 是否在text为空的时候返回final信息, 1->强制返回;0->不强制返回。
    int maxSil      // 最长静音间隔，单位秒，默认10s
    int modelType   // 0->cn; 默认0
    int needPartial // 是否返回partial文本，1->返回，0-> 不返回;默认1
    int needVad     // 是否需要vad;0->关闭;1->开启; 默认1
    int needWords   // 是否返回词语的对齐信息，1->返回， 0->不返回;默认0。
    double vadSilThres // vad断句的累积时间，大于等于0， 如果设置为0，或者没设置，系统默认
}

// 实时语音转文字回调
interface QNAudioToTextCallback {
    void onAudioToText(QNAudioToText audioToText) // 实时转化文字数据

    void onError(int code, String errMsg) // 错误

    void onStart() // 开始成功

    void onStop() // 实时转化结束
}

// 语音识别结果
// 当前片段的结果文字数据，开始到结束过程中会实时返回数据，包含当前一句中的总结果和当前语音片段的结果
class QNAudioToText {
    double startTime // 该片段的起始时间，毫秒
    double endTime   // 该片段的终止时间，毫秒
    int ended      // 是否是websocket最后一条数据,0:非最后一条数据,1: 最后一条数据。
    int endSeq     // 为该文本所在的切片的终点(包含)，否则为-1
    int finalX     // 分片结束,当前消息的transcript为该片段最终结果，否则为partial结果
    int longSil    // 是否长时间静音，0:否;1:是
    int segBegin   // 是否分段开始: 1:是; 0:不是。
    int segIndex   // 是否是vad分段开始说话的开始1:是分段开始说话; 0:不是。
    int spkBegin   // 是否是vad分段开始说话的开始1:是分段开始说话; 0:不是。
    int startSeq   // 该文本所在的切片的起点(包含), 否则为-1
    String uuid    // 服务端生成的uuid
    String transcript // 语音的文本, 如果final=0, 则为partinal结果 (后面可能会更改),final=1为该片段最终结果
    String partialTranscript  // partial结果文本, 开启needpartial后返回
    java.util.List<QNAudioToText.WordsDTO> words // 返回词语的对齐信息, 参数need_words=1时返回详细内存见下表。

    class WordsDTO {
        double segEnd   // 该词语相对整个数据流的起始时间, 毫秒
        double segStart // 该词语相对当前分段的起始时间, 毫秒
        double voiceEnd   // 该词语相对整个数据流的终止时间, 毫秒
        double voiceStart // 该词语相对当前分段的终止时间, 毫秒
        String word // 词语本身，包括标点符号
    }
}
```

```
// example:
QNAudioToTextAnalyzer audioToTextAnalyzer = QNAudioToTextAnalyzer.start(
        audioTrack,//要转化的轨道
        new AudioToTextParam(),//参数设置 可以使用默认
        new QNAudioToTextAnalyzer.QNAudioToTextCallback() {
            @Override
            public void onAudioToText(QNAudioToText audioToText) {}
        }
);
//停止语音转文字
audioToTextAnalyzer.stop()
```

### 人脸对比

```java
class QNFaceComparer {
    // videoTrack - 视频轨道；targetImg - 目标要对比的图片；params - 参数；callback - 回调
    static void run(
            QNTrack videoTrack, android.graphics.Bitmap targetImg,
            QNFaceCompareParam param, QNFaceCompareCallback callback) // 开始一次人脸对比
}

// 人脸对比参数
class QNFaceCompareParam {
    boolean maxFaceA    // 图像 A 中检测到多张人脸时是否取最大区域的人脸作为输出，默认值为 True
    boolean maxFaceB    // 图像 B 中检测到多张人脸时是否取最大区域的人脸作为输出，默认值为 True
    boolean rotateA     // 人脸检测失败时，是否对图像 A 做旋转再检测，旋转角包括 90、180、270 三个角度，默认值为 False
    boolean rotateB     // 人脸检测失败时，是否对图像 B 做旋转再检测，旋转角包括 90、180、270 三个角度，默认值为 False
}

// 人脸对比结果
class QNFaceCompare {
    int errorCode // 请求返回码
    string errorMsg // 错误提示
    double similarity //相似度
}

// 人脸对比回调
interface QNFaceCompareCallback {
    void onResult(QNFaceCompare faceCompare) // 比较结果回调
}
```

```
// example:
QNFaceComparer.run(videoTrack,targetImg,null,new QNIDCardDetector.QNIDCardDetectCallback(){
    @Override
    public void onResult(IDCardDetect idCardDetect){}
});
```

### 人脸检测

```java
class QNFaceDetector {
    // 开始一次人脸检测
    static void run(
            QNTrack videoTrack, QNFaceDetectParams params, QNFaceDetectCallback callback)
}

// 人脸检测参数
class QNFaceDetectParam {
    boolean rotate // 人脸检测失败时，是否对图像 A 做旋转再检测，旋转角包 括 90、180、270 三个角度，默认值为 False
}

// 人脸检测回调
interface QNFaceDetectCallback {
    void onResult(QNFaceDetect faceDetect) // 人脸检测结果
}

// 人脸检测结果
class QNFaceDetect {
    int errorCode   // 请求返回码
    String errorMsg // 错误提示
    int numFace     // 图像中人脸数量
    int rotateAngle // 图像旋转角度
    java.util.List<FaceDTO> faces // [face1,face2,…]，其中 face1,face2,…等为 json 格式，具体格式见下表

    class FaceDTO {
        int age      // 年龄，区间 1-107 岁
        double area // 人脸区域的大小
        double blur // 人脸模糊度，取值范围[0,1]，越大越清晰
        double completeness // 取值0到100；0表示人脸不完整，溢出了图像边界，100 表示人脸是完整的，在图像边界内
        double eye  // 闭眼概率,取值范围[0,100]
        String faceAlignedB64 // 使用 base64 编码的对齐后人脸图片数据
        double faceZize // 人脸尺寸分数，取值分数[0,100]， 越大人脸尺寸越大
        String gender   // 性别，’M’代表男，’F’代表女
        int height       // 人脸框的高度
        double illumination // 人脸光照范围，取值范围[0,100]，越大光照质量越好
        double mouth // 闭嘴概率,取值范围[0,100]
        double pitch // 三维旋转之俯仰角，[-180,180]
        double quality // 人脸综合质量分数，取值范围[0,100], 越大质量越好
        double roll  // 三维旋转之左右旋转角, [-180,180]
        double score // 人脸分数 取值范围 [0,100]
        int width     // 人脸框的宽度
        int x         // 人脸框的左上角 x 坐标
        int y         // 人脸框的左上角 y 坐标
        double yaw   // 三维旋转之旋转角，[-180,180]
        FaceShapeDTO faceShape // 人脸尺寸分数，取值分数[0,100]， 越大人脸尺寸越大


        class FaceShapeDTO {
            java.util.List<FaceProfileDTO> faceProfile
            java.util.List<FaceProfileDTO> leftEye
            java.util.List<FaceProfileDTO> leftEyebrow
            java.util.List<FaceProfileDTO> mouth
            java.util.List<FaceProfileDTO> nose
            java.util.List<FaceProfileDTO> pupil
            java.util.List<FaceProfileDTO> rightEye
            java.util.List<FaceProfileDTO> rightEyebrow

            // 人脸部位坐标
            class FaceProfileDTO {
                int x
                int y
            }
        }
    }
}
```

```
// example:
QNFaceDetector.run(videoTrack,new QNFaceDetectParam(),new QNFaceDetector.QNFaceDetectCallback(){
    @Override
    public void onResult(QNFaceDetect faceDetect){ }
});
```

### 身份证识别

```java
class QNIDCardDetector {
    // 开始一次身份证识别
    static void run(QNTrack videoTrack, QNIDCardDetectParam param, QNIDCardDetectCallback callback)
}

// 身份证识别请求参数
class QNIDCardDetectParam {
    boolean enableBorderCheck // 身份证遮挡检测开关，如果输入图片中的身份证卡片边框不完整则返回告警
    boolean enableDetectCopy  // 复印件、翻拍件检测开关，如果输入图片中的身份证卡片是复印件，则返回告警
    String refSide     // 当图片中同时存在身份证正反面时，通过该参数指定识别的版面:取值'Any' - 识别人像面或国徽面，'F' - 仅 识别人像面，'B' - 仅识别国徽面
    boolean retImage    // 是否返回识别后的切图(切图是指精确剪裁对齐后的身份证正反面图片)，返回格式为 JPEG 格式二进制图片使用 base64 编码后的字符串
    boolean retPortrait // 是否返回身份证(人像面)的人脸图 片，返回格式为 JPEG 格式二进制图片使用 base64 编码后的字符串
}

// 身份证识别结果回调
interface QNIDCardDetectCallback {
    void onResult(QNIDCardDetect idCardDetect)
}

// 身份证识别结果
class QNIDCardDetect {
    int errorCode   // 请求返回码
    String errorMsg // 错误提示
    QNIDCardDetect.ImageResultDTO imageResult // 图片检测结果
    QNIDCardDetect.OCRResultDTO ocrResult // 文字识别结果

    class ImageResultDTO {
        // 框坐标，格式为 [[x0, y0], [x1, y1], [x2, y2], [x3, y3]]
        java.util.List<java.util.List<Integer>> idCardBox // ??? 为什么用数组的数组
        String idcard;    //身份证区域图片，使用Base64 编码后的字符串， 是否返回由请求参数ret_image 决定
        String portrait;//	身份证人像照片，使用Base64 编码后的字符串， 是否返回由请求参数ret_portrait 决定
    }

    class OCRResultDTO {
        String address   // 地址(人像面)
        String birthDate // 生日(人像面) eg. "19900111"
        String gender    // 性别(人像面)
        String idno      // 身份号码(人像面)
        String issuedBy  // 签发机关(国徽面)
        String name      // 姓名(人像面)
        String nation    // 民族(人像面)
        String side      // F-身份证人像面，B-身份 证国徽面
        String validthru // 有效期(国徽面) eg. "20001010-20101009"
    }
}
```

```
// example:
QNIDCardDetector.run(videoTrack,null,new QNIDCardDetector.QNIDCardDetectCallback(){
   @Override
   public void onResult(QNIDCardDetect idCardDetect){ }
});
```

### 光线活体检测

```java
class QNFaceFlashLiveDetector {
    /**
     * 开始活体光线检测
     * @param videoTrack 要检测的视频轨道
     */
    static QNFaceFlashLiveDetector start(QNTrack videoTrack)

    //获取结果识别结果
    void commit(QNFaceFlashLiveCallback callBack)

    //取消
    void cancel()
}

// 回调函数
interface QNFaceFlashLiveCallback {
    //结果回调
    void onResult(QNFaceFlashLive flashLive)
}

//光线活体结果
class QNFaceFlashLive {
    double score      //检测分数
    int passNum    //视频中通过的人脸帧数
    int faceNum    //视频中检测到的人脸帧数
    int errorCode
    String errorMsg
}
```

```
// example:
QNFaceFlashLiveDetector faceFlashLiveDetector = QNFaceFlashLiveDetector.start(localVideoTrack);
//todo 提示活体检测开始
faceFlashLiveDetector.commit{
        faceFlashLive->
        //todo 拿到结果 判断分数是否满足
}
```

### 文字转语音

```java
class QNTextToSpeakAnalyzer {

    /**
     * 开始文字转语音
     * @param ttsParam 参数
     * @param callback 转化结果回调
     */
    static void run(QNTTSParam ttsParam, QNTextToSpeakCallback callback)
}

//文转音回调函数
interface QNTextToSpeakCallback {
    // 结果回调
    void onResult(QNTextToSpeak textToSpeak)
}

//文字转语音参数
class QNTTSParam {
    String text                    // 需要进⾏语⾳合成的⽂本内容，最短1个字，最⻓200字
    QNSpeaker speaker              //发⾳⼈id，⽤于选择不同⻛格的⼈声，⽬前默认为kefu1， 可选的包括female3，female5，female6，male1，male2， male4，kefu1，girl1
    QNAudioEncoding audioEncoding  //合成⾳频格式，⽬前默认为wav，可选的包括wav，pcm，mp3
    int sampleRate = 16000         //合成⾳频的采样率，默认为16000，可选的包括8000，16000， 24000，48000
    int volume = 50                //⾳量⼤⼩，取值范围为0~100，默认为50
    int speed = 0                  //语速，取值范围为-100~100，默认为0
    String voice_id = ""           //语音ID 可空
}

//文字转语音声效枚举
enum QNSpeaker {
    MALE1("male1")        //男声1

    MALE2("male2")        //男声2

    FEMALE3("female3")    //女声3

    MALE4("male4")        //男声4

    FEMALE5("female5")    //女声5

    FEMALE6("female6")    //女声6

    KEFU1("kefu1")        //客服1

    GIRL1("girl1")        //女孩1
    }

//tts 音频编码格式枚举
enum QNAudioEncoding {
    WAV("wav")

    PCM("pcm")

    MP3("mp3")
    }

//文转音结果
class QNTextToSpeak {
    int errorCode            //错误码
    String errorMsg          //提示
    String audioText = ""    //合成的⾳频文本，采⽤base64编码
    byte[] audioBytes        //可播放的音频二进制数据
}
```

```
// example:
QNTTSParam param = new QNTTSParam();
param.text="test";
QNTextToSpeakAnalyzer.run(param){
        textToSpeak->
        //todo 播放音频二进制数据
        play(textToSpeak)
}
```

### 权威人脸对比

```java

public class QNAuthoritativeFaceComparer {

    //开始一次权威人脸
    static void run(QNTrack videoTrack, QNAuthoritativeFaceParam param, QNAuthoritativeFaceComparerCallback callback);

}

//权威人脸对比参数
class QNAuthoritativeFaceParam {
    String realName;//真实名字
    String idCard; //身份证号码
}

//权威人脸对比结果
class QNAuthoritativeFace {
    String sessionID;
    int errorCode;
    String errorMsg;
    double similarity; //相似度
}

//权威人脸结果回调   
interface QNAuthoritativeFaceComparerCallback {
    void onResult(QNAuthoritativeFace authoritativeFace);
}

```

### 活体动作识别加权威人脸对比

```java
class QNAuthorityActionFaceComparer {
    //开一次动作活体加权威人脸对比
    //videoTrack - 视频轨道；faceActionParam - 活体检测参数；authoritativeFaceParam - 权威人脸对比参数；
    static QNAuthorityActionFaceComparer start(QNTrack videoTrack, QNFaceActionLiveParams faceActionParam, QNAuthoritativeFaceParam authoritativeFaceParam) // 开始活体动作检测

    void commit(QNAuthorityActionFaceComparerCallback callback) // 动作结束提交获取识别结果

    void cancel() // 取消
}

//结果回调
interface QNAuthorityActionFaceComparerCallback {
    void onResult(QNFaceActionLive faceActLive, QNAuthoritativeFace authoritativeFace);
}

```

### orc

```java
class QNOCRDetector {

    //开始一次 ocr 识别
    static void run(QNTrack videoTrack, OCRDetectParam param, QNOCRDetectorCallback callback)

}

interface QNOCRDetectorCallback {
    onResult(OCRDetect ocrDetect)
}

class OCRDetectParam {
    //当前图片是不是镜像 在没有调整的情况下 通常前置摄像头是镜像图片,后置摄像头不是
    boolean isMirror = false;
}

//orc结果
class OCRDetect {

    int code;
    String message;
    List<Data> data;

    static class Data {
        int line;                 //行数
        List<List<Integer>> bbox; //坐标
        String text;              //文本 
        double score;             //分数
    }
}
```

### 错误码

```c
业务错误码	信息

//通用:
0	成功
1000	未知异常
1001	音频/视频轨道没有数据返回
1002	音频/视频数据异常

//语音转文字:
2000	网络异常连接中断

//身份证识别:
53090001	请求解析失败
53090002	图片解码错误
53090003	OCR 内部错误
53090004	无法识别的身份证(非中国身份证等)
53090005	参数错误
55060030	鉴权失败
53091001	黑白复印件
53091003	无法检测到人脸
53091004	证件信息缺失或错误
53091005	证件过期
53091006	身份证不完整

//人脸检测:
55060001	请求字段有非法传输
55060002	图片解码失败
55060006	人脸特征提取失败
55060018	人脸配准失败
55060019	人脸检测图片 Base64 解码失败
55060033	人脸图片无效

//人脸对比:
55060001	请求字段有非法传输
55060002	图片解码失败
55060028	人脸比对图片 A Base64 解码失败
55060029	人脸比对图片 B Base64 解码失败
55060040	图片A人脸检测失败
55060041	图片B人脸检测失败

// 动作活体检测:
55060001	请求字段有非法传输
55060002	图片解码失败
55060012	点头动作检测失败
55060013	摇头动作检测失败
55060014	眨眼动作检测失败
55060015	张嘴动作检测失败
55060016	不是活体
55060024	视频帧率过低
55060016	动作类型无效

//光线活体
55060001    请求字段有非法传输
55060002	图片解码失败
55060009	视频无效
55060011	视频中人脸检测失败
55060016	不是活体

//文转音
100        请求参数缺失
101        请求参数不合法，⽐如合成⽂本过⻓
102        服务不可⽤
103        语⾳合成错误

//权威人脸

55060001	ERROR_PARAMETER_INVALID	请求字段有非法传输
55060004	FACE_DETECT_FAILED	高清照人脸检测失败
55060006	FEATURE_EXTRACT_FAILED	人脸特征提取失败
55060019	IMAGE_BASE64_DECODE_FAILED	人脸检测图片 Base64 解码失败
55060029	FACE_IDENTIFY_FAILED	人脸鉴别失败
55060044	REALNAME_FORMAT_ERROR	姓名格式不正确
55060045	IDCARD_NUMBER_ERROR	身份证号码有误
55060046	PHOTO_SIZE_NOT_SUITABLE	照片大小不在1kb-30kb的范围内
55060047	AUTH_INFORMATION_NOT_EXISTED	认证信息不存在
55060048	IDCARD_PHOTO_NOT_EXISTED	证件照不存在
55060049	PHOTO_NOT_ACCEPTED	照片质量检验不合格
55060050	PHOTO_MULTIFACE_DETECTED	照片出现多张人脸
```